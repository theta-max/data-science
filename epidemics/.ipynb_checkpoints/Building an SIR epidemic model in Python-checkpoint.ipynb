{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    You can <b>read</b> this Jupyter notebook on my GitHub, but to <b>run the embedded code</b> you'll need to clone the epidemics directory to your local machine. \n",
    "</div>"
   ]
  },
  {
   "attachments": {
    "SIR.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background: the SIR model\n",
    "A common way to model epidemics is to divide a population into compartments, between which individuals move as their infection status changes. A common compartmental model is __[the SIR model](https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SIR_model)__, which stands for **S**usceptible, **I**nfectious, **R**ecovered. Individuals start off susceptible in S, are infected at a given rate and move to I, then recover at a given rate and move to R, where they remain.\n",
    "\n",
    "![SIR.PNG](attachment:SIR.PNG)\n",
    "\n",
    "So we have three compartments (S, I, R) and two parameters (infection rate and recovery rate). This is often modelled using differential equations, but here we're going to simulate infections on a networked population.\n",
    "\n",
    "A naive approach would be to start at time zero with some randomly infected nodes, then find each neighbour of an infected node, then calculate its probability of infection, then change its status if infected, then advance one timestep and repeat…\n",
    "\n",
    "This turns out to be quite inefficient. A lot of the time we do multiple calculations, only for few nodes to actually change status. And we have to repeat all the calculations at each timestep. There is a much more efficient method, using an event queue, which is what we’ll implement below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "If you want to model epidemics on networks with Python, you can simply use the excellent (and appropriately named) package Epidemics on Networks (<strong>pip install EoN</strong>), which contains over 100 functions and is built and maintained by active researchers in the field. If however, like me, you like to learn how things work by building them yourself, then read on…\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages and initialising variables\n",
    "We’ll be using the Python modules NumPy, Pandas, Random, and NetworkX, so let's start by importing them all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's also initialise some variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_rate = 0.5 # the per edge infection rate\n",
    "r_rate = 1 # the recovery rate\n",
    "init = 1 # the number of initial infections\n",
    "max_time = 20 # just in case we do something wrong, it will stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the flow is one-way through an SIR model (see diagram above), the model will always reach an equilibrium with no infections and it should never loop forever. But, belt-and-braces.\n",
    "\n",
    "For our population, you can import network data from a csv and pass it to NetworkX in several ways, but for our purposes we can just get NetworkX to generate a random network for us, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.barabasi_albert_graph(1000,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an event queue\n",
    "We need an empty list to serve as a queue for infection/recovery events (more on this below). Our program will add infection/recovery events to this queue, and iterate through the queue in time order until the queue is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the network\n",
    "Now we’ll need to set all the nodes to “S” status. We can use NetworkX’s `set_node_attributes()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, \"S\", \"status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the infection\n",
    "Now we need to initialise the infection. We can do this by picking a random sample of nodes from the network and setting their status to “I”. We’ll also need to queue recovery events for each infected node, and infection events for each infected node’s neighbours.\n",
    "\n",
    "First, we use the `random.sample()` function to pick `init` nodes from the network `G` and assign them to the variable `init_infecteds`. We can use `nx.nodes(G)`, a NetworkX function which returns an iterator over all the nodes in `G`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_infecteds = random.sample(list(G.nodes()), init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a network where all nodes are susceptible to infection, and a list of which nodes will start out infected (you could initialise differently if you wanted to say, account for some individuals starting out immune)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the initialisation loop\n",
    "Use a for loop to do the following for each node in `init_infecteds`: (1) Set node status to \"I\", (2) queue a recovery event, (3) queue infection events for the neighbours of each infected node.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "We will use a result from probability theory here:<br>\n",
    "\n",
    "<i>If events occur singly, independently, and randomly at a constant rate r (mathematicians call this an “homogenous Poisson point process”), then the waiting times t between events will be randomly distributed according to an exponential distribution with parameter r.</i>\n",
    "</div>\n",
    "\n",
    "This looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in init_infecteds:\n",
    "    G.nodes[node][\"status\"] = \"I\" # set the initially infected nodes\n",
    "    r_time = np.random.exponential(r_rate)\n",
    "    # queue their recovery events\n",
    "    queue.append({\"time\": r_time,\n",
    "                  \"node\": node,\n",
    "                  \"type\": \"R\"})\n",
    "    # and queue infection events for their neighbours\n",
    "    for neighbor in G.neighbors(node):\n",
    "        i_time = np.random.exponential(i_rate)\n",
    "        if i_time < r_time: # they can't infect if they've recovered!\n",
    "            queue.append({\"time\": i_time,\n",
    "                          \"node\": neighbor,\n",
    "                          \"type\": \"I\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the queue by time\n",
    "Now outside the for loops, let’s sort our queue by time. I’ve done it in reverse order so that the last item in the list is the one at the next soonest time. We can do this succinctly with a lambda function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue.sort(key=lambda k: k[\"time\"], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up variables to store the model output\n",
    "We’ll need some counters for nodes of each status, and a list to contain our output, which will contain a single entry - the starting counts at time = 0. After processing each event we’ll update the counts and add another entry to our results list. We’ll use a ‘list of dictionaries’ because these are quick and easy to convert to a Pandas DataFrame for analysis and plotting later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_count = nx.number_of_nodes(G) - init\n",
    "i_count = init\n",
    "r_count = 0\n",
    "output = [{\"time\": 0, \"S\": s_count, \"I\": i_count, \"R\": r_count}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew! We’re all initialised and ready for the main loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the main loop\n",
    "Conceptually, what follows is quite simple:\n",
    "\n",
    "- We select the next soonest event in our queue.\n",
    "- If it’s a recovery event, we check if the node is infected and if so, set it to recovered.\n",
    "- If it’s an infection event, we check if the node is susceptible, and if so infect it, then queue infection events for all its neighbours like we did above.\n",
    "- We remove the event from the queue, add status counts to our output, and keep looping until we run out of events in queue (or we reach `t_max`), at which point the model run is complete.\n",
    "\n",
    "It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "while queue and queue[-1][\"time\"] < max_time:\n",
    "    # unpack the event variables from the queued event\n",
    "    time, node, event_type = (queue[-1][\"time\"],\n",
    "                              queue[-1][\"node\"],\n",
    "                              queue[-1][\"type\"])\n",
    "    # if it's a revovery event and the node is infected, the node recovers\n",
    "    if event_type == \"R\" and G.nodes[node][\"status\"] == \"I\":\n",
    "        G.nodes[node][\"status\"] = event_type\n",
    "        i_count -= 1\n",
    "        r_count += 1\n",
    "        output.append({\"time\": time,\n",
    "                       \"S\": s_count,\n",
    "                       \"I\": i_count,\n",
    "                       \"R\": r_count})\n",
    "    # if it's an infection event and the node is susceptible, infect!\n",
    "    if event_type == \"I\" and G.nodes[node][\"status\"] == \"S\":\n",
    "        G.nodes[node][\"status\"] = event_type\n",
    "        # create a recovery event and queue it\n",
    "        r_time = np.random.exponential(r_rate)\n",
    "        queue.append({\"time\": r_time + time,\n",
    "                      \"node\": node,\n",
    "                      \"type\": \"R\"})\n",
    "        s_count -= 1\n",
    "        i_count += 1\n",
    "        output.append({\"time\": time,\n",
    "                       \"S\": s_count,\n",
    "                       \"I\": i_count,\n",
    "                       \"R\": r_count})\n",
    "        # then create infection events for neighbors\n",
    "        for neighbor in G.neighbors(node):\n",
    "            i_time = np.random.exponential(i_rate)\n",
    "            if i_time < r_time:\n",
    "                queue.append({\"time\": i_time + time,\n",
    "                              \"node\": neighbor,\n",
    "                              \"type\": \"I\"})\n",
    "    # sort the queue by time and pop the event we've just processed\n",
    "    queue.sort(key=lambda k: k[\"time\"], reverse=True)\n",
    "    queue.remove(queue[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to output the results. I found it convenient to output the data as a Pandas DataFrame, so I did it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(output)\n",
    "df.rename(columns={\"S\": \"Susceptible\", \"I\": \"Infected\", \"R\": \"Recovered\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And we're done!\n",
    "\n",
    "I've put all of the above into a function, along with an auxilliary function to help align multiple plotting runs for ease of visualisation. Let's run it and plot some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epidemics import SIR, timeshift\n",
    "\n",
    "runs = 5 # How many model runs we want; bigger numbers take longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "for i in range(runs):\n",
    "    results = SIR(G, i_rate=0.5, r_rate=1, init=5)\n",
    "    results[\"model_run\"] = \"run \" + \"{}\".format(i+1).zfill(3)\n",
    "    timeshift(results, nx.number_of_nodes(G) * 0.05)\n",
    "    output = pd.concat([output, results])\n",
    "\n",
    "output.dropna(inplace=True)\n",
    "output_long = pd.melt(output, id_vars=[\"time\", \"time_adj\", \"model_run\"],\n",
    "                       var_name=\"status\", value_name=\"node_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_context('notebook')\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Seaborn plot\n",
    "ax = plt.gca()\n",
    "colours = [\"amber\", \"red\", \"blue\"]\n",
    "sns.set_palette(sns.xkcd_palette(colours))\n",
    "sns.lineplot(x=\"time_adj\", y=\"node_count\",\n",
    "             hue=\"status\",\n",
    "             units=\"model_run\", estimator=None,\n",
    "             data=output_long,\n",
    "             hue_order=[\"Susceptible\", \"Infected\", \"Recovered\"],\n",
    "             lw=0.5, alpha=5/(runs + 4),\n",
    "             ax=ax)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
